{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce51537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1d063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'E:\\Egyptian National IDs\\model and yolo\\yolov5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa843295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-9-20 Python-3.9.12 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model =torch.hub.load('.', 'custom', path=r'E:\\Egyptian National IDs\\model and yolo\\model\\numbers_detection/best.pt', source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"E:\\Egyptian National IDs\\images for numbers detection model/8.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35076521",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = r\"E:\\Egyptian National IDs\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = r\"E:\\Egyptian National IDs\\test2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in os.listdir(images):\n",
    "    try:\n",
    "        img_path = os.path.join(images, img)\n",
    "        result = model(img_path)\n",
    "        result.show()\n",
    "    except (OSError, cv2.error) as e:\n",
    "        print(f\"Error processing image {img}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f588d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in os.listdir(images):\n",
    "    try:\n",
    "        img_path = os.path.join(images, img)\n",
    "        result = model(img_path)\n",
    "        result.show()\n",
    "    except (OSError, cv2.error) as e:\n",
    "        print(f\"Error processing image {img}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7dab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in os.listdir(images):\n",
    "    try:\n",
    "        img_path = os.path.join(images, img)\n",
    "        result = model(img_path)\n",
    "        result.show()\n",
    "    except (OSError, cv2.error) as e:\n",
    "        print(f\"Error processing image {img}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ffbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img = Image.open(\"/content/3.jpg\")\n",
    "    print(\"Image format:\", img.format)\n",
    "except Exception as e:\n",
    "    print(\"Error opening image:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(img)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f33edc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-9-20 Python-3.9.12 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model =torch.hub.load('.', 'custom', path=r'E:\\Egyptian National IDs\\model and yolo\\model\\numbers_recognition/best2.pt', source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d3484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = r\"E:\\Egyptian National IDs\\video_and_frames\\resized_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26cb165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = r\"E:\\Egyptian National IDs\\test3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b696ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = r\"E:\\Egyptian National IDs\\video_and_frames\\resized_images\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
